{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:  [[-0.35999998  0.28      ]]\n",
      "y:  [[0.   0.28]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable([[-0.5, -0.2],\n",
    "                 [-0.3,  0.4],\n",
    "                 [-0.5,  0.2]])\n",
    "b  = tf.Variable([[ 0.1, 0.2]])\n",
    "\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.relu(tf.matmul(X, W) + b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb: ', sess.run(XWb))\n",
    "    print('y: ', sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:  [[-0.35999998  0.28      ]]\n",
      "y:  [[0.41095957 0.5695462 ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable([[-0.5, -0.2],\n",
    "                 [-0.3,  0.4],\n",
    "                 [-0.5,  0.2]])\n",
    "b  = tf.Variable([[ 0.1, 0.2]])\n",
    "\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb: ', sess.run(XWb))\n",
    "    print('y: ', sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "以常態分佈的亂數產生Weight與bias的初始值\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: \n",
      " [[1.5149281  0.70492256]]\n",
      "W: \n",
      " [[-0.74255174 -0.6732924 ]\n",
      " [-0.63858724 -1.2585945 ]\n",
      " [ 0.0305434   0.20695336]]\n",
      "y: \n",
      " [[0.7507109 0.5662747]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b  = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('b: \\n', sess.run(b))\n",
    "    print('W: \\n', sess.run(W))\n",
    "    print('y: \\n', sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: \n",
      " [[1.3664892 0.5064383]]\n",
      "W: \n",
      " [[ 0.05091012  0.7227563 ]\n",
      " [ 0.7991373   2.3279078 ]\n",
      " [-1.1113982  -0.7749314 ]]\n",
      "y: \n",
      " [[0.7506574 0.7213463]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    (_b, _W, _y) = sess.run((b, W, y))\n",
    "    print('b: \\n', _b)\n",
    "    print('W: \\n', _W)\n",
    "    print('y: \\n', _y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "以placeholder傳入神經網路, 使用feed_dict傳入陣列進行運算\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: \n",
      " [[ 1.1307145  -0.43422872]]\n",
      "W: \n",
      " [[ 0.93138516 -0.9746241 ]\n",
      " [-0.10944293 -0.15421388]\n",
      " [-1.6691687  -1.3559676 ]]\n",
      "X: \n",
      " [[0.4 0.5 0.4]]\n",
      "y: \n",
      " [[0.6858697  0.19099277]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.placeholder('float', [None, 3])\n",
    "\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.5, 0.4]])\n",
    "    (_b, _W, _X, _y) = sess.run((b, W, X, y), feed_dict = {X: X_array})\n",
    "    print('b: \\n', _b)\n",
    "    print('W: \\n', _W)\n",
    "    print('X: \\n', _X)\n",
    "    print('y: \\n', _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: \n",
      " [[ 0.60897547 -0.43538427]]\n",
      "W: \n",
      " [[ 1.1215321  -0.38610575]\n",
      " [ 0.28810713 -0.9796834 ]\n",
      " [-1.5747973   1.949394  ]]\n",
      "X: \n",
      " [[ 0.4  0.5  0.4]\n",
      " [ 0.3  0.4  0.5]\n",
      " [ 0.3 -0.4  0.5]]\n",
      "y: \n",
      " [[0.63916063 0.42557934]\n",
      " [0.5678978  0.50790125]\n",
      " [0.51069677 0.69324934]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.placeholder('float', [None, 3])\n",
    "\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.5, 0.4],\n",
    "                        [0.3, 0.4, 0.5],\n",
    "                        [0.3, -0.4, 0.5]])\n",
    "    (_b, _W, _X, _y) = sess.run((b, W, X, y), feed_dict = {X: X_array})\n",
    "    print('b: \\n', _b)\n",
    "    print('W: \\n', _W)\n",
    "    print('X: \\n', _X)\n",
    "    print('y: \\n', _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: \n",
      " [[0.1 0.2]]\n",
      "W: \n",
      " [[-0.5 -0.2]\n",
      " [-0.3  0.4]\n",
      " [-0.5  0.2]]\n",
      "X: \n",
      " [[ 0.4  0.5  0.4]\n",
      " [ 0.3  0.4  0.5]\n",
      " [ 0.3 -0.4  0.5]]\n",
      "y1: \n",
      " [[-0.55        0.2       ]\n",
      " [-0.52        0.20000002]\n",
      " [-0.28       -0.12000001]]\n",
      "y2: \n",
      " [[-0.45000002  0.4       ]\n",
      " [-0.42        0.40000004]\n",
      " [-0.18        0.07999999]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable([[-0.5, -0.2],\n",
    "                 [-0.3,  0.4],\n",
    "                 [-0.5,  0.2]])\n",
    "b  = tf.Variable([[ 0.1, 0.2]])\n",
    "X = tf.placeholder('float', [None, 3])\n",
    "\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y_1 = tf.matmul(X, W)\n",
    "y_2 = tf.matmul(X, W) + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.5, 0.4],\n",
    "                        [0.3, 0.4, 0.5],\n",
    "                        [0.3, -0.4, 0.5]])\n",
    "    (_b, _W, _X, _y1, _y2) = sess.run((b, W, X, y_1, y_2), feed_dict = {X: X_array})\n",
    "    print('b: \\n', _b)\n",
    "    print('W: \\n', _W)\n",
    "    print('X: \\n', _X)\n",
    "    print('y1: \\n', _y1)\n",
    "    print('y2: \\n', _y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "建立layer函數<br>\n",
    "output_dim:　輸出的神經元數量<br>\n",
    "input_dim: 輸入的神經元數量<br>\n",
    "inputs: 輸入的二維陣列placeholderd<br>\n",
    "activation: 傳入啟動函數, 預設是None\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(output_dim, input_dim, inputs, activation = None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer X: \n",
      " [[0.4 0.2 0.4 0.5]]\n",
      "hidden layer h: \n",
      " [[0.         0.24214268 0.        ]]\n",
      "output layer y: \n",
      " [[-1.2301536  2.2799137]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder('float', [None, 4])\n",
    "h = layer(output_dim = 3, input_dim = 4, inputs = X, activation = tf.nn.relu)\n",
    "y = layer(output_dim = 2, input_dim = 3, inputs = h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]])\n",
    "    (layer_X, layer_h, layer_y) = sess.run((X, h, y), feed_dict = {X: X_array})\n",
    "\n",
    "    print('input layer X: \\n', layer_X)\n",
    "    print('hidden layer h: \\n', layer_h)\n",
    "    print('output layer y: \\n', layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(output_dim, input_dim, inputs, activation = None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer X: \n",
      " [[0.4 0.2 0.4 0.5]]\n",
      "W1: \n",
      " [[ 0.9489961   1.4119428   0.36082274]\n",
      " [-0.6305932  -0.91456795 -0.7516897 ]\n",
      " [ 0.7268899   0.46290326 -0.18744408]\n",
      " [ 1.3246216   1.2149867   0.10677125]]\n",
      "b1: \n",
      " [[-0.16265266 -0.67775136 -0.17002924]]\n",
      "hidden layer h: \n",
      " [[1.0438939  0.49676675 0.        ]]\n",
      "W2: \n",
      " [[ 0.2581859  -0.49561837]\n",
      " [-0.66594464  0.22496778]\n",
      " [-1.175611   -1.6157389 ]]\n",
      "b2: \n",
      " [[-0.37398803 -0.4499844 ]]\n",
      "output layer y: \n",
      " [[-0.43528852 -0.85560095]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder('float', [None, 4])\n",
    "h, W1, h1 = layer(output_dim = 3, input_dim = 4, inputs = X, activation = tf.nn.relu)\n",
    "y, W2, h2 = layer(output_dim = 2, input_dim = 3, inputs = h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]])\n",
    "    (layer_X, layer_h, layer_y, W1, b1, W2, b2) = sess.run((X, h, y, W1, h1, W2, h2), feed_dict = {X: X_array})\n",
    "\n",
    "    print('input layer X: \\n', layer_X)\n",
    "    print('W1: \\n', W1)\n",
    "    print('b1: \\n', b1)\n",
    "    print('hidden layer h: \\n', layer_h)\n",
    "    print('W2: \\n', W2)\n",
    "    print('b2: \\n', b2)\n",
    "    print('output layer y: \\n', layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
